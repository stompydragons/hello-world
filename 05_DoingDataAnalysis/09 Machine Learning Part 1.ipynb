{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning Part 1\n",
    "\n",
    "Machine learning is learning from data or examples.\n",
    "\n",
    "The training data is the data used to learn the pattern that can predict outcomes. It consists of two components: the input features (such as age, fare, gender) and the output feature (such as survived/not survived). Input features are also called predictors, because they are used to predict the output. The output is also called response or outcome.\n",
    "\n",
    "The training data can be thought of as a spreadsheet, listing inputs against outputs. Each row is considered an observation or sample. The process of representing each observation as an input is known formally as representation.\n",
    "\n",
    "The process of learning the pattern so it can be used to predict the outcome of unseen combinations of features (instead of looking up known combinations) is called generalisation and is the key to machine learning: this is what allows an ML algorthim to be used in the wild on new data.\n",
    "\n",
    "The test data only has input features, no outcomes. This is the data used to predict the outcomes.\n",
    "\n",
    "The process of using training data to learn patterns is called supervised learning, because the training data has input features and output features.\n",
    "\n",
    "In the Titanic data, the output is either 0 (did not survive) or 1 (survived), which is a discreet output. This is a classification problem - the goal has only two (or more) discreet outcomes, not a range of continuous possibilities.\n",
    "\n",
    "Problems that have continuous real numbers as outcomes are called regression problems. For example, predicting care mileage from a range of possible car features. \n",
    "\n",
    "Classification and regression problems are both supervised learning problems - they both have inputs and outcomes in the training data.\n",
    "\n",
    "\n",
    "### Unsupervised learning\n",
    "Unsupervised learning is used to infer a function to find hidden patterns in 'unlabelled data', i.e. data with no classification or categorisation in the observations. An example of this would be customer segmentation for marketing targeting, for example. This specific type is called clustering: using data to cluster customers according to features, so that different marketing tactics can be aimed at the different groups.\n",
    "\n",
    "\n",
    "## Titanic Challenge\n",
    "\n",
    "This has a binary output, so it is called a binary classification task. It can be trickier to work a problem with more than two classes, but the basic concepts in these notebooks can be applied to a multi-class problem.\n",
    "\n",
    "The pattern used to predict the outcomes is also known as a classifier or classifier model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classifiers\n",
    "\n",
    "If you had a dataset with only two features and plotted it on a graph, the line (or curve. or whatever shape) that separates the group of observations with one outcome from the other observations is called the 'separation boundary'. If you have three features, they can be plotted in three dimensions and the decision boundary becomes a plane. With many features, the bounday becomes a multi-dimensional hyperplane.\n",
    "\n",
    "That boundary is what a machine learning algorirthm is trying to find, so it can accurate;y put new data into one of the categories based on its features.\n",
    "\n",
    "There are many types of classifiers, from simple ones (such as logistic regression) to more complex, fancy onces including support vector machine, neural networks, and random forest classifiers.\n",
    "\n",
    "## Performance metrics\n",
    "\n",
    "To judge which is the best model to use for a problem and pick the right one, you need performance metrics. There are many, but the course I'm doing will focus on the ones that are best for classifier problems, specifically binary classification problems, because it's working on the Titanic challenge dataset.\n",
    "\n",
    "Accuracy is the most commonly used performance metric, and it's the one Kaggle uses for the Titanic challenge. Other metrics included precision and recall.\n",
    "\n",
    "If you have made your predictions and you have access to the actual output, you can compare then to judge the accuracy of the model. Is this why we divide the training data into training and validation sets? The measure is the percentage of predicted outcomes that match the actual outcomes. Accuracy should be as high as possible!\n",
    "\n",
    "Precision is particularly suited to binary classification and it's about how many results were true negative (predicted and actual was negative), true positive, false negative (the model predicted negative, actual was positive), and false positive. You can make a 2x2 table of these counts which is called a **confusion matrix**, because it gives you an idea where the model got confused and produced the wrong outcomes. You can use this to answer questions about the outcomes.\n",
    "\n",
    "What percentage of positive predictions are correct? This is the count of true positive predictions divided by the sume of all predicted positive outcomes (true and false). The percentage is the **precision**.\n",
    "\n",
    "What percentage of positive outcomes were predicted correctly? This is true positive cases divided by the sum of actual positive cases (true positive plus false negative). This fraction is known as **recall**.\n",
    "\n",
    "## Classifier evaluation\n",
    "\n",
    "So how is the model actually evaluated? A popular method of evaluating classifiers is called train-test split. Take the training data and split it into two sets: training and validation/test (not to be confused with the test data from the challenge files). The training data is used to train the model, and then predictions are made using the validation/test dataset. The predictions are compared to the outcomes in the validation/test data to evaluate the model's performance.\n",
    "\n",
    "The common split is 80/20 (80% training). It can be any split you want, but 80/20 is the most common."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## What is a baseline model\n",
    "\n",
    "As best practice, it's a good idea to create a baseline model that doesn't use any machine learning. In a classifier problem, the baseline model always gives the output of the majority class.\n",
    "\n",
    "So in a binary classification example, if the outputs are 1 and 0 and 60 out of 100 observations have an output of 1, then your most basic of baseline model will always return one. It will have an accuracy of 60%. So your machine learning models should have an accuracy of over 60% to perform better than the baseline model, otherwise it makes no sense to use a machine learning model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing data for the model\n",
    "\n",
    "First, import the data and the libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "processed_data_path = os.path.join(os.getcwd(), 'data', 'processed')\n",
    "read_train_path = os.path.join(processed_data_path, 'train.csv')\n",
    "read_test_path = os.path.join(processed_data_path, 'test.csv')\n",
    "\n",
    "train_df = pd.read_csv(read_train_path, index_col='PassengerId')\n",
    "test_df = pd.read_csv(read_test_path, index_col='PassengerId')\n",
    "df = pd.concat([train_df, test_df], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 891 entries, 1 to 891\n",
      "Data columns (total 33 columns):\n",
      "Survived              891 non-null int64\n",
      "Age                   891 non-null float64\n",
      "Fare                  891 non-null float64\n",
      "FamilySize            891 non-null int64\n",
      "IsMother              891 non-null int64\n",
      "IsMale                891 non-null int64\n",
      "Deck_A                891 non-null int64\n",
      "Deck_B                891 non-null int64\n",
      "Deck_C                891 non-null int64\n",
      "Deck_D                891 non-null int64\n",
      "Deck_E                891 non-null int64\n",
      "Deck_F                891 non-null int64\n",
      "Deck_G                891 non-null int64\n",
      "Deck_Z                891 non-null int64\n",
      "Pclass_1              891 non-null int64\n",
      "Pclass_2              891 non-null int64\n",
      "Pclass_3              891 non-null int64\n",
      "Title_Lady            891 non-null int64\n",
      "Title_Master          891 non-null int64\n",
      "Title_Miss            891 non-null int64\n",
      "Title_Mr              891 non-null int64\n",
      "Title_Mrs             891 non-null int64\n",
      "Title_Officer         891 non-null int64\n",
      "Title_Sir             891 non-null int64\n",
      "Fare_Bin_very_low     891 non-null int64\n",
      "Fare_Bin_low          891 non-null int64\n",
      "Fare_Bin_high         891 non-null int64\n",
      "Fare_Bin_very_high    891 non-null int64\n",
      "Embarked_C            891 non-null int64\n",
      "Embarked_Q            891 non-null int64\n",
      "Embarked_S            891 non-null int64\n",
      "AgeState_Adult        891 non-null int64\n",
      "AgeState_Child        891 non-null int64\n",
      "dtypes: float64(2), int64(31)\n",
      "memory usage: 236.7 KB\n"
     ]
    }
   ],
   "source": [
    "train_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 418 entries, 892 to 1309\n",
      "Data columns (total 32 columns):\n",
      "Age                   418 non-null float64\n",
      "Fare                  418 non-null float64\n",
      "FamilySize            418 non-null int64\n",
      "IsMother              418 non-null int64\n",
      "IsMale                418 non-null int64\n",
      "Deck_A                418 non-null int64\n",
      "Deck_B                418 non-null int64\n",
      "Deck_C                418 non-null int64\n",
      "Deck_D                418 non-null int64\n",
      "Deck_E                418 non-null int64\n",
      "Deck_F                418 non-null int64\n",
      "Deck_G                418 non-null int64\n",
      "Deck_Z                418 non-null int64\n",
      "Pclass_1              418 non-null int64\n",
      "Pclass_2              418 non-null int64\n",
      "Pclass_3              418 non-null int64\n",
      "Title_Lady            418 non-null int64\n",
      "Title_Master          418 non-null int64\n",
      "Title_Miss            418 non-null int64\n",
      "Title_Mr              418 non-null int64\n",
      "Title_Mrs             418 non-null int64\n",
      "Title_Officer         418 non-null int64\n",
      "Title_Sir             418 non-null int64\n",
      "Fare_Bin_very_low     418 non-null int64\n",
      "Fare_Bin_low          418 non-null int64\n",
      "Fare_Bin_high         418 non-null int64\n",
      "Fare_Bin_very_high    418 non-null int64\n",
      "Embarked_C            418 non-null int64\n",
      "Embarked_Q            418 non-null int64\n",
      "Embarked_S            418 non-null int64\n",
      "AgeState_Adult        418 non-null int64\n",
      "AgeState_Child        418 non-null int64\n",
      "dtypes: float64(2), int64(30)\n",
      "memory usage: 107.8 KB\n"
     ]
    }
   ],
   "source": [
    "test_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data preparation\n",
    "\n",
    "Most machine learning algorithms expect numerical arrages, so these need to be created for input and output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# this takes all rows and all columns except Survived (i.e. from Age onwards) and creates a matrix of float values\n",
    "X = train_df.loc[:, 'Age':].as_matrix().astype('float')\n",
    "\n",
    "# this creates a flattened one dimensional array (or vector) of floats from the outputs using a numpy function\n",
    "y = train_df['Survived'].ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(891, 32) (891,)\n"
     ]
    }
   ],
   "source": [
    "# both of these are now numpy arrays (a vector in the case of y, because it's one-dimensional) so the shape attribute \n",
    "# can be used.\n",
    "# It's good practice to use uppercase variables for matrices and lower case for vectors\n",
    "print(X.shape, y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(712, 32) (712,)\n",
      "(179, 32) (179,)\n"
     ]
    }
   ],
   "source": [
    "# now split X into training and test data\n",
    "# it's good practice to set the random_state and it ensures you get the same selection each time you run this\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n",
    "print(X_train.shape, y_train.shape)\n",
    "print(X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the mean survival in train: 0.383\n",
      "the mean survival in test: 0.385\n"
     ]
    }
   ],
   "source": [
    "# average survival in the train and test set\n",
    "# use the numpy mean function to get the proportion of positive classes\n",
    "print('the mean survival in train: {0:.3f}'.format(np.mean(y_train)))\n",
    "print('the mean survival in test: {0:.3f}'.format(np.mean(y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ideally, you want the outcomes to be evenly distributed in the train and test datasets, so around 50% positive outcomes. The mean here is 39% (so 39% were 1, 61% were 0), which is imbalanced but useable. Datasets that are even more imbalanced may be hard to work with.\n",
    "\n",
    "For example, in marketing conversion data, the positive outcomes could only be 2-3% of the data. So a different process needs to be followed to build and evaulate models (not covered in the course I'm following)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating a Baseline Model\n",
    "\n",
    "The DummyClassifier in scikit-learn creates a baseline model that can be used for evaluating the performance of the rest of your models. It's slightly more sophisticated than the manual, no code needed baseline above, but not very. However, it is something that can be used for automated comparisons."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# import funcion\n",
    "from sklearn.dummy import DummyClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# create model, specify most_frequent because the baseline model we want will always output the majority class\n",
    "model_dummy = DummyClassifier(strategy='most_frequent', random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DummyClassifier(constant=None, random_state=0, strategy='most_frequent')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train model\n",
    "model_dummy.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score for baseline model: 0.61\n"
     ]
    }
   ],
   "source": [
    "# basic evaluation\n",
    "# this will predict the output for the test dat and then compare predicted output with actual output\n",
    "# this will outout the accuracy, which is the default score\n",
    "print('score for baseline model: {0:.2f}'.format(model_dummy.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What this score is saying is that if you always predict 0 for survived, the majority class, you will have 61% accuracy for the model. Very important! Now you'll know if machine learning algorithms are really better.\n",
    "\n",
    "There are features in scikit-learn that will allow you to get other performance metrics, such as precision, confusion matrix, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# performance metrics\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, precision_score, recall_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy for baseline model: 0.61\n"
     ]
    }
   ],
   "source": [
    "# accuracy score\n",
    "print('accuracy for baseline model: {0:.2f}'.format(accuracy_score(y_test, model_dummy.predict(X_test))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy for baseline model:\n",
      " [[110   0]\n",
      " [ 69   0]]\n"
     ]
    }
   ],
   "source": [
    "# confusion matrix\n",
    "print('accuracy for baseline model:\\n {0}'.format(confusion_matrix(y_test, model_dummy.predict(X_test))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision for baseline model: 0.00\n",
      "recall for baseline model: 0.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/katherinejay/anaconda3/envs/analysis/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "# from the matrix, we are always predicting zero (negative outcome) never positive\n",
    "# precision and recall score\n",
    "print('precision for baseline model: {0:.2f}'.format(precision_score(y_test, model_dummy.predict(X_test))))\n",
    "print('recall for baseline model: {0:.2f}'.format(recall_score(y_test, model_dummy.predict(X_test))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating output for a Kaggle submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# converting the Kaggle test data (not the validation/test data) to a matrix\n",
    "test_X = test_df.as_matrix().astype('float')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# get predictions\n",
    "predictions = model_dummy.predict(test_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# for a Kaggle submission, each prediction needs to be attached to a PassengerId\n",
    "df_submission = pd.DataFrame({'PassengerId': test_df.index, 'Survived': predictions})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>892</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>893</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>894</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>895</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>896</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived\n",
       "0          892         0\n",
       "1          893         0\n",
       "2          894         0\n",
       "3          895         0\n",
       "4          896         0"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "submission_data_path = os.path.join(os.getcwd(), 'data', 'external')\n",
    "submission_file_path = os.path.join(submission_data_path, '01_dummy.csv')\n",
    "\n",
    "# setting index to False prevents an extra column being added to the output\n",
    "df_submission.to_csv(submission_file_path, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You could also write a function to do all of this and then just call the function, which will be useful because it's the same process that will be used for future models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_submission_file(model, filename):\n",
    "    # converting to the matrix\n",
    "    test_X = test_df.as_matrix().astype('float')\n",
    "    # get predictions\n",
    "    predictions = model.predict(test_X)\n",
    "    # submission dataframe\n",
    "    df_submission = pd.DataFrame({'PassengerId': test_df.index, 'Survived': predictions})\n",
    "    # submission file\n",
    "    submission_data_path = os.path.join(os.getcwd(), 'data', 'external')\n",
    "    submission_file_path = os.path.join(submission_data_path, filename)\n",
    "    #write to file\n",
    "    df_submission.to_csv(submission_file_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "get_submission_file(model_dummy, '01_dummy.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Logistic Regression model\n",
    "\n",
    "The logistic regression model uses a sigmoid function to predict the probability of an output. Thinking about it on a graph, if you plot the sigmoid curve (probability on y axis, your input on x axis) then for any given input, you can find the point where that input value bisects the curve -> probability value. If you set the threshold to 0.5, then anything over the threshold is class 1 and anything less than 0.5 is class 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# import function\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# create model\n",
    "model_lr_1 = LogisticRegression(random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=0, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train model\n",
    "model_lr_1.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy for logistic regression - version 1: 0.83\n"
     ]
    }
   ],
   "source": [
    "# accuracy score\n",
    "print('accuracy for logistic regression - version 1: {0:.2f}'.format(model_lr_1.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The accuracy score for this model is 83%, which is better than the baseline model of 0.62%. Hooray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy for logistic regression - version 1: 0.83\n",
      "accuracy for logistic regression - version 1:\n",
      " [[95 15]\n",
      " [15 54]]\n",
      "precision for logistic regression - version 1: 0.78\n",
      "recall for logistic regression - version 1: 0.78\n"
     ]
    }
   ],
   "source": [
    "# accuracy score\n",
    "print('accuracy for logistic regression - version 1: {0:.2f}'.format(accuracy_score(y_test, model_lr_1.predict(X_test))))\n",
    "# confusion matrix\n",
    "print('accuracy for logistic regression - version 1:\\n {0}'.format(confusion_matrix(y_test, model_lr_1.predict(X_test))))# from the matrix, we are always predicting zero (negative outcome) never positive\n",
    "# precision and recall score\n",
    "print('precision for logistic regression - version 1: {0:.2f}'.format(precision_score(y_test, model_lr_1.predict(X_test))))\n",
    "print('recall for logistic regression - version 1: {0:.2f}'.format(recall_score(y_test, model_lr_1.predict(X_test))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.02842268,  0.00455451, -0.50009089,  0.6178132 , -0.81392331,\n",
       "         0.12845079, -0.17281789, -0.39317834,  0.52159979,  1.09941224,\n",
       "         0.40341217, -0.18345052, -0.30036043,  0.96533486,  0.48256744,\n",
       "        -0.34483448,  0.28089598,  1.21761328,  0.56363966, -1.44586305,\n",
       "         1.07245548, -0.11273708, -0.47293646,  0.16255648,  0.24716933,\n",
       "         0.28009428,  0.41324773,  0.49183528,  0.46198829,  0.14924424,\n",
       "         0.37283516,  0.73023265]])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# coefficient properties/parameters\n",
    "model_lr_1.coef_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Second Kaggle submission file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "get_submission_file(model_lr_1, '02_lr.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This submission got a 79% score on Kaggle. Hooray!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
